{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from statistics import mean\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GexfID</th>\n",
       "      <th>Title</th>\n",
       "      <th>IMDB_id</th>\n",
       "      <th>ReleaseDate</th>\n",
       "      <th>Slug</th>\n",
       "      <th>WeightedDegree</th>\n",
       "      <th>Modularity</th>\n",
       "      <th>PathLength</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>ClusteringCoefficient</th>\n",
       "      <th>ConnectedComponents</th>\n",
       "      <th>Density</th>\n",
       "      <th>Edges</th>\n",
       "      <th>Characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10 Things I Hate About You</td>\n",
       "      <td>147800</td>\n",
       "      <td>1999</td>\n",
       "      <td>10-Things-I-Hate-About-You</td>\n",
       "      <td>13,040</td>\n",
       "      <td>0,194</td>\n",
       "      <td>1,779</td>\n",
       "      <td>3,000</td>\n",
       "      <td>0,567</td>\n",
       "      <td>3,000</td>\n",
       "      <td>0,233</td>\n",
       "      <td>225</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>488478</td>\n",
       "      <td>2007</td>\n",
       "      <td>12</td>\n",
       "      <td>4,227</td>\n",
       "      <td>0,517</td>\n",
       "      <td>2,170</td>\n",
       "      <td>3,000</td>\n",
       "      <td>0,610</td>\n",
       "      <td>6,000</td>\n",
       "      <td>0,077</td>\n",
       "      <td>102</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Twelve and Holding</td>\n",
       "      <td>417385</td>\n",
       "      <td>2005</td>\n",
       "      <td>Twelve-and-Holding</td>\n",
       "      <td>7,333</td>\n",
       "      <td>0,473</td>\n",
       "      <td>2,449</td>\n",
       "      <td>4,000</td>\n",
       "      <td>0,593</td>\n",
       "      <td>2,000</td>\n",
       "      <td>0,140</td>\n",
       "      <td>139</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>127 Hours</td>\n",
       "      <td>1542344</td>\n",
       "      <td>2010</td>\n",
       "      <td>127-Hours</td>\n",
       "      <td>3,833</td>\n",
       "      <td>0,160</td>\n",
       "      <td>1,722</td>\n",
       "      <td>2,000</td>\n",
       "      <td>0,339</td>\n",
       "      <td>4,000</td>\n",
       "      <td>0,152</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1492: Conquest of Paradise</td>\n",
       "      <td>103594</td>\n",
       "      <td>1992</td>\n",
       "      <td>1492:-Conquest-of-Paradise</td>\n",
       "      <td>7,941</td>\n",
       "      <td>0,350</td>\n",
       "      <td>2,043</td>\n",
       "      <td>4,000</td>\n",
       "      <td>0,705</td>\n",
       "      <td>1,000</td>\n",
       "      <td>0,153</td>\n",
       "      <td>164</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GexfID                       Title  IMDB_id  ReleaseDate  ... ConnectedComponents Density Edges Characters\n",
       "0       1  10 Things I Hate About You   147800         1999  ...               3,000   0,233   225         25\n",
       "1       2                          12   488478         2007  ...               6,000   0,077   102         42\n",
       "2       3          Twelve and Holding   417385         2005  ...               2,000   0,140   139         26\n",
       "3       5                   127 Hours  1542344         2010  ...               4,000   0,152    33         11\n",
       "4       6  1492: Conquest of Paradise   103594         1992  ...               1,000   0,153   164         34\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df = pd.read_csv(\"data/network_metadata.tab\", sep=\"\\t\")\n",
    "metadata_df.loc[:, \"IMDB_id\"] = metadata_df[\"IMDB_id\"].str[2:].astype('int')\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data_df = pd.read_json(\"data/gexf_imdb_metadata.json\", orient='index')\n",
    "# imdb_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Robin McCann\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(metadata_df, imdb_data_df, left_on=\"IMDB_id\", right_on=\"movie_id\")\n",
    "df.loc[:,'directors-writers'] = df.loc[:,'directors'] + df.loc[:,'writers']\n",
    "for i in range(len(df)):\n",
    "    df.loc[:,'directors-writers'][i] = list(set(df.loc[:,'directors-writers'][i]))\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A graph where nodes are movie titles and are conneted if they share a director or a writer.\n",
    "Movies_Graph = nx.Graph()\n",
    "titles = df.loc[:,'Title']\n",
    "for title in titles:\n",
    "    Movies_Graph.add_node(title)\n",
    "\n",
    "    \n",
    "# Add node if two movies share a director or a writer\n",
    "# Edge weight = number of directors/writers in common \n",
    "for i in range(len(df)):\n",
    "    for j in range(i+1, len(df)):\n",
    "        title_i = titles[i]\n",
    "        title_j = titles[j]\n",
    "        dirwri_i = df.loc[i,'directors-writers']\n",
    "        dirwri_j = df.loc[j,'directors-writers']\n",
    "        intersection = set.intersection(set(dirwri_i), set(dirwri_j))\n",
    "        if intersection:\n",
    "            Movies_Graph.add_edge(title_i, title_j, weight=len(intersection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Map node name to node_name, for saving\n",
    "mapping = {}\n",
    "for node in Movies_Graph:\n",
    "    mapping[node] = str(node).replace(\" \", \"_\")\n",
    "\n",
    "\n",
    "H=nx.relabel_nodes(Movies_Graph, mapping)\n",
    "nx.write_adjlist(H, \"data/movies_graph.adjlist\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# make subset of G that is ~50 nodes\n",
    "Movies_Graph_subset = copy.deepcopy(Movies_Graph)\n",
    "i=0\n",
    "for node in Movies_Graph:\n",
    "    if Movies_Graph.degree(node) < 12:\n",
    "        Movies_Graph_subset.remove_node(node)\n",
    "\n",
    "# print(len(Movies_Graph))\n",
    "# print(len(Movies_Graph_subset))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A graph where nodes are directors or writers and are connected if they have collaborated on a movie\n",
    "\n",
    "# Get all unique directors and writers\n",
    "writer_movies_map = {}\n",
    "Writers_Graph = nx.Graph()\n",
    "Directors_writers_unique = set()\n",
    "for dw_list in df.loc[:,'directors-writers']:\n",
    "    for dw in dw_list:\n",
    "        Directors_writers_unique.add(dw)\n",
    "        \n",
    "# Add all writer nodes and make dictionary for every movie worked on by said writer\n",
    "for dw in Directors_writers_unique:\n",
    "    writer_movies_map[dw] = []\n",
    "    Writers_Graph.add_node(dw)\n",
    "    for i in range(len(df)):\n",
    "        if dw in df.loc[i,'directors-writers']:\n",
    "            writer_movies_map.get(dw).append(df.loc[i,'Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_movies_map = {}\n",
    "directors_unique = set()\n",
    "for d_list in df.loc[:,'directors']:\n",
    "    for d in d_list:\n",
    "        directors_unique.add(d)\n",
    "        \n",
    "for d in directors_unique:\n",
    "    director_movies_map[d] = []\n",
    "    for i in range(len(df)):\n",
    "        if d in df.loc[i,'directors']:\n",
    "            director_movies_map.get(d).append(df.loc[i,'Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "writers = list(writer_movies_map.keys())\n",
    "\n",
    "# Add edges between writers with weight equal to the number of movies they have collaborated on\n",
    "for i in range(len(writers)):\n",
    "    for j in range(i+1, len(writers)):\n",
    "        writer_i = writers[i]\n",
    "        writer_j = writers[j]\n",
    "        movies_i = writer_movies_map[writer_i]\n",
    "        movies_j = writer_movies_map[writer_j]\n",
    "        intersection = set.intersection(set(movies_i), set(movies_j))\n",
    "        if intersection:\n",
    "            Writers_Graph.add_edge(writer_i, writer_j, weight=len(intersection))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Map node name to node_name, for saving\n",
    "mapping = {}\n",
    "for node in Writers_Graph:\n",
    "    mapping[node] = str(node).replace(\" \", \"_\")\n",
    "\n",
    "\n",
    "H=nx.relabel_nodes(Writers_Graph, mapping)\n",
    "nx.write_adjlist(H, \"data/writers_graph.adjlist\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1461\n"
     ]
    }
   ],
   "source": [
    "# print(len(Writers_Graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_connection_with_edges(G, min_weight=None, max_weight=None, figsize=None, layout=None,\n",
    "                               c=100, font_size=16, font_color='orange'):\n",
    "    if figsize is not None:\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "    pos = layout or nx.random_layout(G)\n",
    "    \n",
    "    weights = {(u, v): d[\"weight\"] for (u, v, d) in G.edges(data=True)}\n",
    "    if min_weight is not None:\n",
    "        weights = {k: v for k, v in weights.items() if v > min_weight}\n",
    "    if max_weight is not None:\n",
    "        weights = {k: v for k, v in weights.items() if v <= max_weight}\n",
    "    filtered_edges = list(weights.keys())\n",
    "    \n",
    "    t = np.array(list(weights.values()))\n",
    "    normalized_weights = c*t/t.sum()\n",
    "\n",
    "    nx.draw(G, pos=pos, edgelist=filtered_edges, font_color=font_color, width=normalized_weights,\n",
    "            with_labels=True, font_weight='bold', font_size=font_size)\n",
    "\n",
    "    nx.draw_networkx_edge_labels(G,\n",
    "                                 pos=pos,\n",
    "                                 edge_labels=weights)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_connection_with_edges(Writers_Graph, min_weight=2, c=10, font_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steven Spielberg, degree: 22\n",
      "Ridley Scott, degree: 20\n",
      "Ronald Shusett, degree: 19\n",
      "David Koepp, degree: 19\n",
      "Dan O'Bannon, degree: 17\n",
      "Michael Mann, degree: 16\n",
      "Brian De Palma, degree: 16\n",
      "James Cameron, degree: 15\n",
      "David Fincher, degree: 15\n",
      "George Lucas, degree: 15\n"
     ]
    }
   ],
   "source": [
    "# Writers ordered by most connections\n",
    "all_writers = list(Writers_Graph.nodes())\n",
    "all_writers_sorted = sorted(all_writers, key=lambda x: Writers_Graph.degree(x), reverse=True)                  \n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"{all_writers_sorted[i]}, degree: {Writers_Graph.degree(all_writers_sorted[i])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indiana Jones and the Kingdom of the Crystal Skull, degree: 22\n",
      "Raiders of the Lost Ark, degree: 20\n",
      "Mission: Impossible, degree: 20\n",
      "Jurassic Park, degree: 18\n",
      "The Lost World: Jurassic Park, degree: 18\n",
      "War of the Worlds, degree: 18\n",
      "Indiana Jones and the Last Crusade, degree: 17\n",
      "Aliens, degree: 16\n",
      "Indiana Jones and the Temple of Doom, degree: 16\n",
      "Minority Report, degree: 16\n"
     ]
    }
   ],
   "source": [
    "# Movies ordered by most connections\n",
    "all_movies = list(Movies_Graph.nodes())\n",
    "all_movies_sorted = sorted(all_movies, key=lambda x: Movies_Graph.degree(x), reverse=True)                  \n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"{all_movies_sorted[i]}, degree: {Movies_Graph.degree(all_movies_sorted[i])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For a given writer, compile some statistics about the movies he/she has made\n",
    "def get_writer_data(writer=\"Steven Spielberg\"):\n",
    "    director = writer\n",
    "    stats = {\n",
    "        \"director\": director,\n",
    "        \"number_of_movies\": 0,\n",
    "        \"number_of_characters\": [],\n",
    "        \"number_of_communities\": [],\n",
    "        \"clustering\": [],\n",
    "        \"modularity\": [],\n",
    "        \"diameter\": [],\n",
    "        \"density\": []\n",
    "    }\n",
    "\n",
    "    movies = director_movies_map[director]\n",
    "    for movie in movies:\n",
    "        for i in range(len(df)):\n",
    "            if df.loc[i,\"Title\"] == movie:\n",
    "                gexf_id = df.loc[i,\"GexfID\"]\n",
    "                index = i\n",
    "                break\n",
    "        G = nx.read_gexf(f\"data/gexf/{gexf_id}.gexf\", relabel=True)\n",
    "        # find out stuff about the graph here and save it\n",
    "        stats[\"number_of_characters\"].append(df.loc[index, \"Characters\"])\n",
    "        stats[\"number_of_communities\"].append(len(list(nx.algorithms.community.modularity_max.greedy_modularity_communities(G))))\n",
    "        stats[\"clustering\"].append(float(df.loc[index, \"ClusteringCoefficient\"].replace(',','.')))\n",
    "        stats[\"modularity\"].append(float(df.loc[index, \"Modularity\"].replace(',','.')))\n",
    "        stats[\"diameter\"].append(float(df.loc[index, \"Diameter\"].replace(',','.')))\n",
    "        stats[\"density\"].append(float(df.loc[index, \"Density\"].replace(',','.')))\n",
    "        stats[\"number_of_movies\"] =stats[\"number_of_movies\"] + 1\n",
    "    \n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Directors = {}\n",
    "for director in director_movies_map.keys():\n",
    "    All_Directors[director]=get_writer_data(director)\n",
    "with open('data/director_summary.p', 'wb') as fp:\n",
    "    pickle.dump(All_Directors, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
